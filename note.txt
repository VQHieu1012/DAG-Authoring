#### Airflow level ####

# the max number of concurrency tasks your airflow instance can run at the same time
# it means your airflow instance can run at most 32 tasks at the same time
parallelism = 32 


# the max number of tasks your dag can run at the same time
# you won't have more than 16 tasks run for all dagrun for your dag
dag_concurrency = 16


# the number of dagruns that can run at the same time for a given dag
max_active_run_per_dag = 16


#### DAG level ####

# at most 2 tasks run at the same time across all of the dagruns of the given dag [concurrency]
# 1 dagrun at the time for this specific dag [max_active_runs]
with (..., concurrency=2, max_active_runs=1)

#### Task level ####

# only 1 instance of task at the time across all dagruns of your dag [task_concurency]
PythonOperator(task_id="", task_concurency=1, pool='default_pool')

# pool_slots defined the slot the task will take in the pool while task is running
PythonOperator(task_id="", task_concurency=1, pool='default_pool', pool_slots=3)

# In tag, we have "priority_weight", but this only takes effect if these tasks share the same pool

# Keyword for task: depends_on_past=True
for example:
dagrun #1: t1 >> t2 >> t3
dagrun #2: t1 >> t2 >> t3

If t1_#1 fail, t1_#2 will not trigger and won't have any state -> you need to set timeout for task

# Keyword for task: wait_for_downstream=True (this will set depends_on_past=True automatically)
for example: 
t1_#1 is succeed and t2_#1 is directly downstream of the t1_#1 and succeed, 
t1_#2 will be triggered

In case you need to run multiple dagrun and access same resources, you may come up with race condition and so on,
So in order to ensure that your dag are not modifying the same resources at the same time, you can consider using this.


# Combo keywords for Retry task
retries: number of time a task retries
retry_delay: delay time between each Retry
retry_exponential_backoff: Set to True and the time delay between 2 retries will increase
max_retry_delay: max delay time between 2 retries

# If a task running longer than you expected, you can use SLAs to receive notification.
What is the different between SLAs and timeout?
SLAs will keep the task running, timeout will mark the task as failed instead.
The time SLAs used is related to the execution date, not the time which the task starts
For example: if you want to verify that your DAG will only run within 10 minutes, 
    you can modify the sla in your last task = 10
    
    In case you set sla of the second task is 5 minutes, but the first task takes 6 minutes to execute,
    you will miss the sla. To handle this situation, you can use sla_miss_callback=_python_function 
                            (this parameter is defined in DAG level, and it is applied for all of your tasks,
                            you can't have different callback for different tasks)

If you trigger your DAG manually (it means your DAG is not triggered by the Scheduler), your SLAs won't be checked.
If you want to receive the notification from SLA, you need to configure the SMTP server and email parameter for your DAG

